{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6457,
     "status": "ok",
     "timestamp": 1686777840219,
     "user": {
      "displayName": "Liu Zeyu",
      "userId": "17925325437793044714"
     },
     "user_tz": -60
    },
    "id": "KFzwkhOc0oxw",
    "outputId": "0ef9f688-f4c6-4797-97de-5f52850c3ab5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting ipynb\n",
      "  Downloading ipynb-0.5.1-py3-none-any.whl (6.9 kB)\n",
      "Installing collected packages: ipynb\n",
      "Successfully installed ipynb-0.5.1\n"
     ]
    }
   ],
   "source": [
    "pip install ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xorfr3yGl8ZH"
   },
   "outputs": [],
   "source": [
    "from pandas_datareader import data as pdr\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, balanced_accuracy_score\n",
    "from datetime import date\n",
    "import glob, os\n",
    "from joblib import dump, load\n",
    "from ipynb.fs.full.Data_Preparation import getFilenames\n",
    "from ipynb.fs.full.Data_Preparation import getProcessedData\n",
    "from operator import concat\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2D1zDtSXoXfb"
   },
   "outputs": [],
   "source": [
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zwaorqiul8nQ"
   },
   "outputs": [],
   "source": [
    "# Define the list of currency tickers used in the analysis\n",
    "fx_tic = ['USDEUR',\n",
    "            'USDJPY',\n",
    "            'USDGBP',\n",
    "            'USDCHF',\n",
    "            'USDNZD',\n",
    "            'USDCAD',\n",
    "            'USDSEK',\n",
    "            'USDDKK',\n",
    "            'USDNOK',\n",
    "            'EURJPY',\n",
    "            'EURGBP',\n",
    "            'EURCHF',\n",
    "            'EURNZD',\n",
    "            'EURCAD',\n",
    "            'EURSEK',\n",
    "            'EURDKK',\n",
    "            'EURNOK']\n",
    "\n",
    "# Create a dictionary that maps each currency ticker to an index\n",
    "fx_dic = {'USDEUR': 0,\n",
    " 'USDJPY': 1,\n",
    " 'USDGBP': 2,\n",
    " 'USDCHF': 3,\n",
    " 'USDNZD': 4,\n",
    " 'USDCAD': 5,\n",
    " 'USDSEK': 6,\n",
    " 'USDDKK': 7,\n",
    " 'USDNOK': 8,\n",
    " 'EURJPY': 9,\n",
    " 'EURGBP': 10,\n",
    " 'EURCHF': 11,\n",
    " 'EURNZD': 12,\n",
    " 'EURCAD': 13,\n",
    " 'EURSEK': 14,\n",
    " 'EURDKK': 15,\n",
    " 'EURNOK': 16}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TKbPTLNto96W"
   },
   "outputs": [],
   "source": [
    "# Create a dictionary that defines the top 20 features for each currency ticker. These features are selected by SFFS\n",
    "feat_20={\n",
    "    'USDEUR': [0, 6, 11, 12, 16, 22, 23, 24, 25, 28, 30, 31, 33, 38, 44, 45, 48, 49, 54, 59],\n",
    "    'USDJPY': [0, 13, 14, 15, 16, 18, 19, 20, 21, 22, 26, 28, 31, 33, 35, 38, 41, 47, 51, 53],\n",
    "    'USDGBP': [1, 2, 5, 13, 16, 18, 23, 24, 25, 31, 35, 36, 38, 41, 42, 46, 48, 51, 52, 54],\n",
    "    'USDCHF': [2, 5, 7, 8, 10, 11, 17, 25, 27, 35, 41, 43, 47, 48, 51, 52, 53, 54, 55, 57],\n",
    "    'USDNZD': [5, 6, 8, 10, 13, 14, 17, 20, 21, 23, 24, 25, 33, 37, 40, 43, 51, 52, 53, 57],\n",
    "    'USDCAD': [5, 8, 10, 11, 17, 18, 20, 23, 24, 25, 31, 33, 35, 40, 42, 52, 54, 55, 56, 57],\n",
    "    'USDSEK': [7, 8, 10, 11, 17, 18, 21, 23, 24, 25, 26, 27, 31, 33, 35, 40, 42, 43, 53, 55],\n",
    "    'USDDKK': [1, 3, 7, 13, 14, 17, 22, 23, 26, 27, 28, 29, 30, 31, 35, 44, 48, 51, 52, 53],\n",
    "    'USDNOK': [0, 2, 4, 5, 7, 15, 17, 18, 20, 22, 23, 26, 27, 33, 34, 37, 47, 49, 51, 57],\n",
    "    'EURJPY': [0, 1, 4, 9, 13, 20, 21, 23, 24, 25, 26, 29, 31, 41, 44, 47, 51, 53, 54, 56],\n",
    "    'EURGBP': [4, 5, 7, 8, 13, 17, 18, 20, 21, 23, 24, 25, 27, 41, 42, 47, 51, 52, 54, 55],\n",
    "    'EURCHF': [4, 11, 12, 14, 17, 18, 19, 26, 29, 32, 33, 34, 39, 40, 45, 47, 49, 50, 51, 52],\n",
    "    'EURNZD': [8, 9, 10, 11, 16, 18, 21, 23, 26, 28, 31, 35, 36, 38, 46, 50, 51, 52, 53, 55],\n",
    "    'EURCAD': [5, 8, 10, 11, 18, 20, 21, 23, 24, 25, 26, 28, 32, 33, 41, 42, 43, 46, 48, 58],\n",
    "    'EURSEK': [2, 4, 8, 10, 11, 13, 15, 20, 22, 23, 33, 39, 40, 41, 44, 48, 51, 54, 55, 59],\n",
    "    'EURDKK': [1, 6, 8, 10, 17, 21, 26, 30, 31, 35, 37, 43, 44, 45, 47, 48, 50, 51, 55, 58],\n",
    "    'EURNOK': [2, 8, 10, 11, 13, 17, 18, 21, 23, 24, 25, 40, 41, 42, 43, 47, 53, 56, 57, 58]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_XpDlVgkpdhS"
   },
   "source": [
    "# 1. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GSr93lskpYhn"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NVRTv23wpYkU"
   },
   "outputs": [],
   "source": [
    "# Non-linear SVM Model\n",
    "def svmnon_cap(stock_name, upload = False):\n",
    "    # Data split\n",
    "    X_train, X_val1, X_val2, X_test, y_train, y_val1, y_val2, y_test = getProcessedData(getFilenames(fx_tic)[fx_dic[stock_name]])\n",
    "    # For each market, we only use top 20 features selected by SFFS.\n",
    "    X_train = X_train.iloc[:,feat_20[stock_name]]\n",
    "    X_val1 = X_val1.iloc[:,feat_20[stock_name]]\n",
    "    X_val2 = X_val2.iloc[:,feat_20[stock_name]]\n",
    "    X_test = X_test.iloc[:,feat_20[stock_name]]\n",
    "\n",
    "    # Check if the model should be loaded directly\n",
    "    if upload == True:\n",
    "        # For ensure that the model does not change when it is used again and is easy to reproduce.\n",
    "        svm = load(path + '/model_weights/' + stock_name +'svmnon.h5')\n",
    "        y_pred = svm.predict(X_val2)\n",
    "        # Calculating the accuracy score\n",
    "        test_score = svm.score(X_val2,y_val2)\n",
    "        # Calculating the balanced accuracy score\n",
    "        balanced_score1 = balanced_accuracy_score(y_val2, y_pred)\n",
    "    \n",
    "    # Otherwise, train the model from scratch\n",
    "    elif upload == False:\n",
    "        best_score = 0\n",
    "\n",
    "        # Grid search for best parameters\n",
    "        for gamma in [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100]:\n",
    "            for C in [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100]:\n",
    "                svm = SVC(gamma=gamma, C=C,kernel = 'rbf')\n",
    "                svm.fit(X_train, y_train)\n",
    "                score = svm.score(X_val1, y_val1)\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_parameters = {'C': C, 'gamma': gamma}\n",
    "        C1 = best_parameters['C']\n",
    "        gamma1 = best_parameters['gamma']\n",
    "        # Training the SVM model with best parameters\n",
    "        svm = SVC(gamma=gamma1, C=C1,kernel = 'rbf')\n",
    "        svm.fit(X_train, y_train)\n",
    "\n",
    "        # Save as a h5 format file\n",
    "        path1 = path + '/model_weights/' + stock_name +'svmnon.h5'\n",
    "        dump(svm, path1)\n",
    "\n",
    "        y_pred = svm.predict(X_val2)\n",
    "        # Calculating the accuracy score\n",
    "        test_score = svm.score(X_val2,y_val2)\n",
    "        # Calculating the balanced accuracy score\n",
    "        balanced_score1 = balanced_accuracy_score(y_val2, y_pred)\n",
    "    else:\n",
    "        print('argument upload should be True or False')\n",
    "\n",
    "    return test_score, balanced_score1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4eSU8fgpqFV"
   },
   "source": [
    "# 2. LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u0pFZCRTpitJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xFl0Q1g_psJJ"
   },
   "outputs": [],
   "source": [
    "# Logistic Regression Model\n",
    "def lr_cap(stock_name, upload = False):\n",
    "    # Data split\n",
    "    X_train, X_val1, X_val2, X_test, y_train, y_val1, y_val2, y_test = getProcessedData(getFilenames(fx_tic)[fx_dic[stock_name]])\n",
    "    # For each market, we only use top 20 features selected by SFFS.\n",
    "    X_train = X_train.iloc[:,feat_20[stock_name]]\n",
    "    X_val1 = X_val1.iloc[:,feat_20[stock_name]]\n",
    "    X_val2 = X_val2.iloc[:,feat_20[stock_name]]\n",
    "    X_test = X_test.iloc[:,feat_20[stock_name]]\n",
    "\n",
    "    # Check if the model should be loaded directly\n",
    "    if upload == True:\n",
    "        # For ensure that the model does not change when it is used again and is easy to reproduce.\n",
    "        lg1 = load(path + '/model_weights/' + stock_name +'lr.h5')\n",
    "        # Calculating the accuracy score\n",
    "        y_pred = lg1.predict(X_val2)\n",
    "        # Calculating the accuracy score\n",
    "        test_score = lg1.score(X_val2,y_val2)\n",
    "        # Calculating the balanced accuracy score\n",
    "        balanced_score1 = balanced_accuracy_score(y_val2, y_pred)\n",
    "    \n",
    "    # Otherwise, train the model from scratch\n",
    "    elif upload == False:\n",
    "        lg = LogisticRegression()\n",
    "        best_score = 0\n",
    "\n",
    "        for C in [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000]:\n",
    "            lg = LogisticRegression(penalty='l1', solver='saga', C=C ,max_iter=8000)\n",
    "            lg.fit(X_train, y_train)\n",
    "            score = lg.score(X_val1, y_val1)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_parameters = {'C': C}\n",
    "        C1 = best_parameters['C']\n",
    "        lg1 = LogisticRegression(penalty='l1', solver='saga', C=C1 ,max_iter=8000)\n",
    "        lg1.fit(X_train, y_train)\n",
    "\n",
    "        path1 = path + '/model_weights/' + stock_name +'lr.h5'\n",
    "        dump(lg1, path1)\n",
    "\n",
    "        y_pred = lg1.predict(X_val2)\n",
    "        # Calculating the accuracy score\n",
    "        test_score = lg1.score(X_val2,y_val2)\n",
    "        # Calculating the balanced accuracy score\n",
    "        balanced_score1 = balanced_accuracy_score(y_val2, y_pred)\n",
    "    else:\n",
    "        print('argument upload should be True or False')\n",
    "\n",
    "    return test_score, balanced_score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rJpwPsSIpsLy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y_gg3LALA-pI"
   },
   "source": [
    "# 3.LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GHTRa7T0A-wf"
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TKPoulh5A-y6"
   },
   "outputs": [],
   "source": [
    "# Linear Discriminant Analysis Model\n",
    "def lda_cap(stock_name, upload = False):\n",
    "    # Data split\n",
    "    X_train, X_val1, X_val2, X_test, y_train, y_val1, y_val2, y_test = getProcessedData(getFilenames(fx_tic)[fx_dic[stock_name]])\n",
    "    # For each market, we only use top 20 features selected by SFFS.\n",
    "    X_train = X_train.iloc[:,feat_20[stock_name]]\n",
    "    X_val1 = X_val1.iloc[:,feat_20[stock_name]]\n",
    "    X_val2 = X_val2.iloc[:,feat_20[stock_name]]\n",
    "    X_test = X_test.iloc[:,feat_20[stock_name]]\n",
    "\n",
    "    # Check if the model should be loaded directly\n",
    "    if upload == True:\n",
    "        # For ensure that the model does not change when it is used again and is easy to reproduce.\n",
    "        lda = load(path + '/model_weights/' + stock_name +'lda.h5')\n",
    "        y_pred = lda.predict(X_val2)\n",
    "        # Calculating the accuracy score\n",
    "        test_score = lda.score(X_val2,y_val2)\n",
    "        # Calculating the balanced accuracy score\n",
    "        balanced_score1 = balanced_accuracy_score(y_val2, y_pred)\n",
    "        \n",
    "    # Otherwise, train the model from scratch\n",
    "    elif upload == False:\n",
    "        lda = LinearDiscriminantAnalysis()\n",
    "        X_train1 = pd.concat([X_train, X_val1],axis=0)\n",
    "        y_train1 = pd.concat([y_train, y_val1],axis=0)\n",
    "        lda.fit(X_train1, y_train1)\n",
    "\n",
    "        path1 = path + '/model_weights/' + stock_name +'lda.h5'\n",
    "        dump(lda, path1)\n",
    "\n",
    "        y_pred = lda.predict(X_val2)\n",
    "        # Calculating the accuracy score\n",
    "        test_score = lda.score(X_val2,y_val2)\n",
    "        # Calculating the balanced accuracy score\n",
    "        balanced_score1 = balanced_accuracy_score(y_val2, y_pred)\n",
    "    else:\n",
    "        print('argument upload should be True or False')\n",
    "\n",
    "    return test_score, balanced_score1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f4aVpUCaA-1Z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YnBIzNnDBB6l"
   },
   "source": [
    "# 4.QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BUA7F2A9BBhe"
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uUbw2dHvBr0V"
   },
   "outputs": [],
   "source": [
    "# Quadratic Discriminant Analysis Model\n",
    "def qda_cap(stock_name, upload = False):\n",
    "    # Data split\n",
    "    X_train, X_val1, X_val2, X_test, y_train, y_val1, y_val2, y_test = getProcessedData(getFilenames(fx_tic)[fx_dic[stock_name]])\n",
    "    # For each market, we only use top 20 features selected by SFFS.\n",
    "    X_train = X_train.iloc[:,feat_20[stock_name]]\n",
    "    X_val1 = X_val1.iloc[:,feat_20[stock_name]]\n",
    "    X_val2 = X_val2.iloc[:,feat_20[stock_name]]\n",
    "    X_test = X_test.iloc[:,feat_20[stock_name]]\n",
    "\n",
    "    # Check if the model should be loaded directly\n",
    "    if upload == True:\n",
    "        # For ensure that the model does not change when it is used again and is easy to reproduce.\n",
    "        qda = load(path + '/model_weights/' + stock_name +'qda.h5')\n",
    "        y_pred = qda.predict(X_val2)\n",
    "        # Calculating the accuracy score\n",
    "        test_score = qda.score(X_val2,y_val2)\n",
    "        # Calculating the balanced accuracy score\n",
    "        balanced_score1 = balanced_accuracy_score(y_val2, y_pred)\n",
    "        \n",
    "    # Otherwise, train the model from scratch\n",
    "    elif upload == False:\n",
    "        qda = QuadraticDiscriminantAnalysis()\n",
    "        X_train1 = pd.concat([X_train, X_val1],axis=0)\n",
    "        y_train1 = pd.concat([y_train, y_val1],axis=0)\n",
    "        qda.fit(X_train1, y_train1)\n",
    "\n",
    "        path1 = path + '/model_weights/' + stock_name +'qda.h5'\n",
    "        dump(qda, path1)\n",
    "\n",
    "        y_pred = qda.predict(X_val2)\n",
    "        # Calculating the accuracy score\n",
    "        test_score = qda.score(X_val2,y_val2)\n",
    "        # Calculating the balanced accuracy score\n",
    "        balanced_score1 = balanced_accuracy_score(y_val2, y_pred)\n",
    "    else:\n",
    "        print('argument upload should be True or False')\n",
    "\n",
    "    return test_score, balanced_score1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pPdb5Q9QBr3I"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "erUnZ1MOwmhx"
   },
   "source": [
    "# 5.Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T7P-Wplrwr-A"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OQmM5Y23pYpJ"
   },
   "outputs": [],
   "source": [
    "# Random Forest Model\n",
    "def rf_cap(stock_name, upload = False):\n",
    "    # Data split\n",
    "    X_train, X_val1, X_val2, X_test, y_train, y_val1, y_val2, y_test = getProcessedData(getFilenames(fx_tic)[fx_dic[stock_name]])\n",
    "    # For each market, we only use top 20 features selected by SFFS.\n",
    "    X_train = X_train.iloc[:,feat_20[stock_name]]\n",
    "    X_val1 = X_val1.iloc[:,feat_20[stock_name]]\n",
    "    X_val2 = X_val2.iloc[:,feat_20[stock_name]]\n",
    "    X_test = X_test.iloc[:,feat_20[stock_name]]\n",
    "\n",
    "    # Check if the model should be loaded directly\n",
    "    if upload == True:\n",
    "        # For ensure that the model does not change when it is used again and is easy to reproduce.\n",
    "        rf1 = load(path + '/model_weights/' + stock_name +'rf.h5')\n",
    "        y_pred = rf1.predict(X_val2)\n",
    "        # Calculating the accuracy score\n",
    "        test_score = rf1.score(X_val2,y_val2)\n",
    "        # Calculating the balanced accuracy score\n",
    "        balanced_score1 = balanced_accuracy_score(y_val2, y_pred)\n",
    "        \n",
    "    # Otherwise, train the model from scratch\n",
    "    elif upload == False:\n",
    "        best_score = 0\n",
    "        # Grid search to find the best hyperparameters for the Random Forest\n",
    "        # 'bootstrap': Whether bootstrap samples are used when building trees\n",
    "        for bootstrap in [True, False]:\n",
    "            # 'max_features': The number of features to consider when looking for the best split\n",
    "            for max_features in ['auto', 'sqrt']:\n",
    "                # 'max_depth': Maximum depth of the tree\n",
    "                for max_depth in [3,5,7,9]:\n",
    "                    # 'min_samples_leaf': Minimum number of samples required at the leaf node\n",
    "                    for min_samples_leaf in [1, 2, 4]:\n",
    "                        # 'min_samples_split': Minimum number of samples required to split an internal node\n",
    "                        for min_samples_split in [2, 5, 10]:\n",
    "                                rf = RandomForestClassifier(bootstrap=bootstrap, max_features=max_features, max_depth=max_depth,\n",
    "                                                          min_samples_leaf=min_samples_leaf, min_samples_split=min_samples_split,\n",
    "                                                          n_estimators = int(np.sqrt(len(X_train.columns))))\n",
    "                                rf.fit(X_train, y_train)\n",
    "                                score = rf.score(X_val1, y_val1)\n",
    "                                # Update best parameters if current score is better\n",
    "                                if score > best_score:\n",
    "                                    best_score = score\n",
    "                                    best_parameters = {'bootstrap': bootstrap, 'max_features': max_features, 'max_depth': max_depth,\n",
    "                                                      'min_samples_leaf': min_samples_leaf, 'min_samples_split': min_samples_split,\n",
    "                                                      }\n",
    "        max_features1 = best_parameters['max_features']\n",
    "        bootstrap1 = best_parameters['bootstrap']\n",
    "        max_depth1 = best_parameters['max_depth']\n",
    "        bootstrap1 = best_parameters['bootstrap']\n",
    "        min_samples_leaf1 = best_parameters['min_samples_leaf']\n",
    "        min_samples_split1 = best_parameters['min_samples_split']\n",
    "        # Training the model with the best parameters\n",
    "        rf1 = RandomForestClassifier(bootstrap=bootstrap1, max_features=max_features1, max_depth=max_depth1,\n",
    "                                                          min_samples_leaf=min_samples_leaf1, min_samples_split=min_samples_split1,\n",
    "                                                          n_estimators = int(np.sqrt(len(X_train.columns))))\n",
    "        rf1.fit(X_train, y_train)\n",
    "        # Saving the model\n",
    "        path1 = path + '/model_weights/' + stock_name +'rf.h5'\n",
    "        dump(rf1, path1)\n",
    "\n",
    "        y_pred = rf1.predict(X_val2)\n",
    "        # Calculating the accuracy score\n",
    "        test_score = rf1.score(X_val2,y_val2)\n",
    "        # Calculating the balanced accuracy score\n",
    "        balanced_score1 = balanced_accuracy_score(y_val2, y_pred)\n",
    "    else:\n",
    "        print('argument upload should be True or False')\n",
    "\n",
    "    return test_score, balanced_score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cVpBpJ2oo9_I"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NvqKFPT0yhzA"
   },
   "source": [
    "# 6.XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y44tQqF6yhIf"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oVJlgz-byhLi"
   },
   "outputs": [],
   "source": [
    "# XGBoost Model\n",
    "def xgb_cap(stock_name, upload = False):\n",
    "    # Data split\n",
    "    X_train, X_val1, X_val2, X_test, y_train, y_val1, y_val2, y_test = getProcessedData(getFilenames(fx_tic)[fx_dic[stock_name]])\n",
    "    # For each market, we only use top 20 features selected by SFFS.\n",
    "    X_train = X_train.iloc[:,feat_20[stock_name]]\n",
    "    X_val1 = X_val1.iloc[:,feat_20[stock_name]]\n",
    "    X_val2 = X_val2.iloc[:,feat_20[stock_name]]\n",
    "    X_test = X_test.iloc[:,feat_20[stock_name]]\n",
    "\n",
    "    # Check if the model should be loaded directly\n",
    "    if upload == True:\n",
    "        # For ensure that the model does not change when it is used again and is easy to reproduce.\n",
    "        xgb_model = load(path + '/model_weights/' + stock_name +'xgb.h5')\n",
    "        y_pred = xgb_model.predict(X_val2)\n",
    "        # Calculating the accuracy score\n",
    "        test_score = xgb_model.score(X_val2,y_val2)\n",
    "        # Calculating the balanced accuracy score\n",
    "        balanced_score1 = balanced_accuracy_score(y_val2, y_pred)\n",
    "    \n",
    "    # Otherwise, train the model from scratch\n",
    "    elif upload == False:\n",
    "        best_score = 0\n",
    "        # Grid search to find the best hyperparameters for the XGBoost\n",
    "        # 'max_depth': Maximum depth of a tree\n",
    "        for max_depth in [3,5,7,9]:\n",
    "            # 'min_child_weight': Minimum sum of instance weight needed in a child\n",
    "            for min_child_weight in [1, 2, 4]:\n",
    "                # 'gamma': Regularization parameter\n",
    "                for gamma in [0, 0.1, 0.2]:\n",
    "                    # 'subsample': Proportion of training data to grow trees and prevent overfitting\n",
    "                    for subsample in [0.6, 0.8, 1]:\n",
    "                        # 'colsample_bytree': Subsample ratio of columns when constructing each tree\n",
    "                        for colsample_bytree in [0.6, 0.8, 1]:\n",
    "                            # 'learning_rate': Shrinks the feature weights to make the boosting process more conservative\n",
    "                            for learning_rate in [0.001, 0.01, 0.1]:\n",
    "                                xgb_model = xgb.XGBClassifier(learning_rate=learning_rate, max_depth=max_depth,\n",
    "                                                              min_child_weight=min_child_weight, gamma=gamma,\n",
    "                                                              subsample=subsample, colsample_bytree=colsample_bytree,\n",
    "                                                              use_label_encoder=False, eval_metric='logloss',\n",
    "                                                              n_estimators = int(np.sqrt(len(X_train.columns))))\n",
    "                                xgb_model.fit(X_train, y_train)\n",
    "                                score = xgb_model.score(X_val1, y_val1)\n",
    "                                # Update best parameters if current score is better\n",
    "                                if score > best_score:\n",
    "                                    best_score = score\n",
    "                                    best_parameters = {'max_depth': max_depth, 'min_child_weight': min_child_weight,\n",
    "                                                      'gamma': gamma, 'subsample': subsample, 'colsample_bytree': colsample_bytree,\n",
    "                                                      'learning_rate': learning_rate}\n",
    "        # Training the model with the best parameters\n",
    "        xgb_model = xgb.XGBClassifier(learning_rate=best_parameters['learning_rate'], max_depth=best_parameters['max_depth'],\n",
    "                                      min_child_weight=best_parameters['min_child_weight'], gamma=best_parameters['gamma'],\n",
    "                                      subsample=best_parameters['subsample'], colsample_bytree=best_parameters['colsample_bytree'],\n",
    "                                      use_label_encoder=False, eval_metric='logloss',\n",
    "                                      n_estimators = int(np.sqrt(len(X_train.columns))))\n",
    "        xgb_model.fit(X_train, y_train)\n",
    "        # Saving the model\n",
    "        path1 = path + '/model_weights/' + stock_name +'xgb.h5'\n",
    "        dump(xgb_model, path1)\n",
    "\n",
    "        y_pred = xgb_model.predict(X_val2)\n",
    "        # Calculating the accuracy score\n",
    "        test_score = xgb_model.score(X_val2,y_val2)\n",
    "        # Calculating the balanced accuracy score\n",
    "        balanced_score1 = balanced_accuracy_score(y_val2, y_pred)\n",
    "    else:\n",
    "        print('argument upload should be True or False')\n",
    "\n",
    "    return test_score, balanced_score1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i_tUbdm_yhVc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R-KpB7zbCDp6"
   },
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YHuMc3OkTB31"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QYmGYX6d-2o1"
   },
   "outputs": [],
   "source": [
    "# Lists to store accuracy scores and balanced accuracy scores for each model and market\n",
    "Stnm = fx_tic\n",
    "svmnon=[]\n",
    "lr=[]\n",
    "lda = []\n",
    "qda = []\n",
    "rf=[]\n",
    "xgboost=[]\n",
    "svmnon_balance=[]\n",
    "lr_balance=[]\n",
    "lda_balance = []\n",
    "qda_balance = []\n",
    "rf_balance = []\n",
    "xgboost_balance = []\n",
    "\n",
    "# Loop through each market\n",
    "for name in fx_tic:\n",
    "    a1,b1 = svmnon_cap(name)\n",
    "    a2,b2 = lr_cap(name)\n",
    "    a3,b3 = lda_cap(name)\n",
    "    a4,b4 = qda_cap(name)\n",
    "    a5,b5 = rf_cap(name)\n",
    "    a6,b6 = xgb_cap(name)\n",
    "\n",
    "    # Append scores to the lists\n",
    "    svmnon.append(a1)\n",
    "    lr.append(a2)\n",
    "    lda.append(a3)\n",
    "    qda.append(a4)\n",
    "    rf.append(a5)\n",
    "    xgboost.append(a6)\n",
    "\n",
    "    svmnon_balance.append(b1)\n",
    "    lr_balance.append(b2)\n",
    "    lda_balance.append(b3)\n",
    "    qda_balance.append(b4)\n",
    "    rf_balance.append(b5)\n",
    "    xgboost_balance.append(b6)\n",
    "\n",
    "\n",
    "# Create a dataframe to compile all the accuracy scores\n",
    "acc_df=pd.DataFrame(zip(Stnm,svmnon, svmnon_balance, lr, lr_balance, lda, lda_balance, qda, qda_balance, rf, rf_balance, xgboost, xgboost_balance),columns=['Stock','SVM Gaussian Kernel','SVM Gaussian Kernel balance',\n",
    "                                                      'Logistic Regression','Logistic Regression balance','LDA','LDA balance','QDA','QDA balance','Random Forest','Random Forest balance','XGBoost','XGBoost balance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 661
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1686165335714,
     "user": {
      "displayName": "Liu Zeyu",
      "userId": "17925325437793044714"
     },
     "user_tz": -60
    },
    "id": "QNu9W_ayCOSh",
    "outputId": "1e05af73-4250-417a-f0ad-f2bc12390892",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-e664ba84-8763-4486-90bb-7f854d80d96f\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock</th>\n",
       "      <th>SVM Gaussian Kernel</th>\n",
       "      <th>SVM Gaussian Kernel balance</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Logistic Regression balance</th>\n",
       "      <th>LDA</th>\n",
       "      <th>LDA balance</th>\n",
       "      <th>QDA</th>\n",
       "      <th>QDA balance</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Random Forest balance</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>XGBoost balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USDEUR</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.535897</td>\n",
       "      <td>0.529991</td>\n",
       "      <td>0.492308</td>\n",
       "      <td>0.494395</td>\n",
       "      <td>0.525641</td>\n",
       "      <td>0.522889</td>\n",
       "      <td>0.510256</td>\n",
       "      <td>0.500727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USDJPY</td>\n",
       "      <td>0.485897</td>\n",
       "      <td>0.505691</td>\n",
       "      <td>0.478205</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.501282</td>\n",
       "      <td>0.505092</td>\n",
       "      <td>0.482051</td>\n",
       "      <td>0.472331</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.490580</td>\n",
       "      <td>0.510256</td>\n",
       "      <td>0.518171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USDGBP</td>\n",
       "      <td>0.524359</td>\n",
       "      <td>0.501700</td>\n",
       "      <td>0.523077</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.517949</td>\n",
       "      <td>0.513599</td>\n",
       "      <td>0.484615</td>\n",
       "      <td>0.492528</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.496007</td>\n",
       "      <td>0.488462</td>\n",
       "      <td>0.474146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USDCHF</td>\n",
       "      <td>0.506410</td>\n",
       "      <td>0.516176</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.499485</td>\n",
       "      <td>0.497436</td>\n",
       "      <td>0.505821</td>\n",
       "      <td>0.542308</td>\n",
       "      <td>0.535737</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.519838</td>\n",
       "      <td>0.489744</td>\n",
       "      <td>0.497466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USDNZD</td>\n",
       "      <td>0.535897</td>\n",
       "      <td>0.504808</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.511538</td>\n",
       "      <td>0.503434</td>\n",
       "      <td>0.506410</td>\n",
       "      <td>0.510474</td>\n",
       "      <td>0.469231</td>\n",
       "      <td>0.475446</td>\n",
       "      <td>0.524359</td>\n",
       "      <td>0.524210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>USDCAD</td>\n",
       "      <td>0.491026</td>\n",
       "      <td>0.490906</td>\n",
       "      <td>0.494872</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.488462</td>\n",
       "      <td>0.489604</td>\n",
       "      <td>0.496154</td>\n",
       "      <td>0.497035</td>\n",
       "      <td>0.505128</td>\n",
       "      <td>0.505234</td>\n",
       "      <td>0.528205</td>\n",
       "      <td>0.528734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>USDSEK</td>\n",
       "      <td>0.496154</td>\n",
       "      <td>0.496154</td>\n",
       "      <td>0.496154</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.494872</td>\n",
       "      <td>0.495651</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.512003</td>\n",
       "      <td>0.484615</td>\n",
       "      <td>0.485078</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>0.508906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>USDDKK</td>\n",
       "      <td>0.491026</td>\n",
       "      <td>0.511982</td>\n",
       "      <td>0.460256</td>\n",
       "      <td>0.494931</td>\n",
       "      <td>0.484615</td>\n",
       "      <td>0.496378</td>\n",
       "      <td>0.502564</td>\n",
       "      <td>0.487404</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>0.509768</td>\n",
       "      <td>0.534615</td>\n",
       "      <td>0.537478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>USDNOK</td>\n",
       "      <td>0.526923</td>\n",
       "      <td>0.527684</td>\n",
       "      <td>0.496154</td>\n",
       "      <td>0.496745</td>\n",
       "      <td>0.521795</td>\n",
       "      <td>0.521108</td>\n",
       "      <td>0.514103</td>\n",
       "      <td>0.513710</td>\n",
       "      <td>0.474359</td>\n",
       "      <td>0.474305</td>\n",
       "      <td>0.528205</td>\n",
       "      <td>0.529081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EURJPY</td>\n",
       "      <td>0.515385</td>\n",
       "      <td>0.504264</td>\n",
       "      <td>0.515385</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.469231</td>\n",
       "      <td>0.460831</td>\n",
       "      <td>0.484615</td>\n",
       "      <td>0.489418</td>\n",
       "      <td>0.476923</td>\n",
       "      <td>0.468767</td>\n",
       "      <td>0.510256</td>\n",
       "      <td>0.504580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EURGBP</td>\n",
       "      <td>0.539744</td>\n",
       "      <td>0.498264</td>\n",
       "      <td>0.543590</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.524359</td>\n",
       "      <td>0.507990</td>\n",
       "      <td>0.546154</td>\n",
       "      <td>0.505962</td>\n",
       "      <td>0.523077</td>\n",
       "      <td>0.504333</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>0.499417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>EURCHF</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.465385</td>\n",
       "      <td>0.475699</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.520279</td>\n",
       "      <td>0.489744</td>\n",
       "      <td>0.494224</td>\n",
       "      <td>0.501282</td>\n",
       "      <td>0.510439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>EURNZD</td>\n",
       "      <td>0.515385</td>\n",
       "      <td>0.499552</td>\n",
       "      <td>0.521795</td>\n",
       "      <td>0.519381</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.509980</td>\n",
       "      <td>0.465385</td>\n",
       "      <td>0.480593</td>\n",
       "      <td>0.502564</td>\n",
       "      <td>0.503028</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.487163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EURCAD</td>\n",
       "      <td>0.523077</td>\n",
       "      <td>0.506604</td>\n",
       "      <td>0.521795</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.521795</td>\n",
       "      <td>0.519261</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.493001</td>\n",
       "      <td>0.506410</td>\n",
       "      <td>0.506982</td>\n",
       "      <td>0.524359</td>\n",
       "      <td>0.522054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>EURSEK</td>\n",
       "      <td>0.535897</td>\n",
       "      <td>0.529005</td>\n",
       "      <td>0.520513</td>\n",
       "      <td>0.508570</td>\n",
       "      <td>0.537179</td>\n",
       "      <td>0.533652</td>\n",
       "      <td>0.526923</td>\n",
       "      <td>0.513481</td>\n",
       "      <td>0.505128</td>\n",
       "      <td>0.506724</td>\n",
       "      <td>0.496154</td>\n",
       "      <td>0.494232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>EURDKK</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.504192</td>\n",
       "      <td>0.497436</td>\n",
       "      <td>0.464134</td>\n",
       "      <td>0.626923</td>\n",
       "      <td>0.504150</td>\n",
       "      <td>0.610256</td>\n",
       "      <td>0.503896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>EURNOK</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.514145</td>\n",
       "      <td>0.529487</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.537179</td>\n",
       "      <td>0.531391</td>\n",
       "      <td>0.502564</td>\n",
       "      <td>0.496731</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.470064</td>\n",
       "      <td>0.517949</td>\n",
       "      <td>0.514901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e664ba84-8763-4486-90bb-7f854d80d96f')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-e664ba84-8763-4486-90bb-7f854d80d96f button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-e664ba84-8763-4486-90bb-7f854d80d96f');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "     Stock  SVM Gaussian Kernel  SVM Gaussian Kernel balance  \\\n",
       "0   USDEUR             0.516667                     0.500000   \n",
       "1   USDJPY             0.485897                     0.505691   \n",
       "2   USDGBP             0.524359                     0.501700   \n",
       "3   USDCHF             0.506410                     0.516176   \n",
       "4   USDNZD             0.535897                     0.504808   \n",
       "5   USDCAD             0.491026                     0.490906   \n",
       "6   USDSEK             0.496154                     0.496154   \n",
       "7   USDDKK             0.491026                     0.511982   \n",
       "8   USDNOK             0.526923                     0.527684   \n",
       "9   EURJPY             0.515385                     0.504264   \n",
       "10  EURGBP             0.539744                     0.498264   \n",
       "11  EURCHF             0.483333                     0.500000   \n",
       "12  EURNZD             0.515385                     0.499552   \n",
       "13  EURCAD             0.523077                     0.506604   \n",
       "14  EURSEK             0.535897                     0.529005   \n",
       "15  EURDKK             0.630769                     0.500000   \n",
       "16  EURNOK             0.516667                     0.514145   \n",
       "\n",
       "    Logistic Regression  Logistic Regression balance       LDA  LDA balance  \\\n",
       "0              0.516667                     0.500000  0.535897     0.529991   \n",
       "1              0.478205                     0.500000  0.501282     0.505092   \n",
       "2              0.523077                     0.500000  0.517949     0.513599   \n",
       "3              0.487179                     0.499485  0.497436     0.505821   \n",
       "4              0.533333                     0.500000  0.511538     0.503434   \n",
       "5              0.494872                     0.500000  0.488462     0.489604   \n",
       "6              0.496154                     0.500000  0.494872     0.495651   \n",
       "7              0.460256                     0.494931  0.484615     0.496378   \n",
       "8              0.496154                     0.496745  0.521795     0.521108   \n",
       "9              0.515385                     0.500000  0.469231     0.460831   \n",
       "10             0.543590                     0.500000  0.524359     0.507990   \n",
       "11             0.483333                     0.500000  0.465385     0.475699   \n",
       "12             0.521795                     0.519381  0.512821     0.509980   \n",
       "13             0.521795                     0.500000  0.521795     0.519261   \n",
       "14             0.520513                     0.508570  0.537179     0.533652   \n",
       "15             0.630769                     0.500000  0.633333     0.504192   \n",
       "16             0.529487                     0.500000  0.537179     0.531391   \n",
       "\n",
       "         QDA  QDA balance  Random Forest  Random Forest balance   XGBoost  \\\n",
       "0   0.492308     0.494395       0.525641               0.522889  0.510256   \n",
       "1   0.482051     0.472331       0.483333               0.490580  0.510256   \n",
       "2   0.484615     0.492528       0.512821               0.496007  0.488462   \n",
       "3   0.542308     0.535737       0.512821               0.519838  0.489744   \n",
       "4   0.506410     0.510474       0.469231               0.475446  0.524359   \n",
       "5   0.496154     0.497035       0.505128               0.505234  0.528205   \n",
       "6   0.512821     0.512003       0.484615               0.485078  0.507692   \n",
       "7   0.502564     0.487404       0.507692               0.509768  0.534615   \n",
       "8   0.514103     0.513710       0.474359               0.474305  0.528205   \n",
       "9   0.484615     0.489418       0.476923               0.468767  0.510256   \n",
       "10  0.546154     0.505962       0.523077               0.504333  0.507692   \n",
       "11  0.516667     0.520279       0.489744               0.494224  0.501282   \n",
       "12  0.465385     0.480593       0.502564               0.503028  0.487179   \n",
       "13  0.500000     0.493001       0.506410               0.506982  0.524359   \n",
       "14  0.526923     0.513481       0.505128               0.506724  0.496154   \n",
       "15  0.497436     0.464134       0.626923               0.504150  0.610256   \n",
       "16  0.502564     0.496731       0.487179               0.470064  0.517949   \n",
       "\n",
       "    XGBoost balance  \n",
       "0          0.500727  \n",
       "1          0.518171  \n",
       "2          0.474146  \n",
       "3          0.497466  \n",
       "4          0.524210  \n",
       "5          0.528734  \n",
       "6          0.508906  \n",
       "7          0.537478  \n",
       "8          0.529081  \n",
       "9          0.504580  \n",
       "10         0.499417  \n",
       "11         0.510439  \n",
       "12         0.487163  \n",
       "13         0.522054  \n",
       "14         0.494232  \n",
       "15         0.503896  \n",
       "16         0.514901  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C0hZV4TBCObu"
   },
   "outputs": [],
   "source": [
    "acc_df.to_csv(path + '/ml_acc_df_new_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
